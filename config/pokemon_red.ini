[base]
package = pokemon_red
env_name = pokemon_red
policy_name = Policy
rnn_name = Recurrent

[train]
total_timesteps = 10_000_000_000
num_envs = 768 # 192 # 96
num_workers = 24
env_batch_size = 32
zero_copy = False
update_epochs = 3
gamma = 0.998
batch_size = 65536
minibatch_size = 2048
compile = True
learning_rate = 2.0e-4
anneal_lr = False
swarm = False
device = cuda
plot_activations = False
save_embeddings = False

[wrappers]
stream_wrapper = True
stream_wrapper_name = leanke
obs_wrapper = False # add_boey_obs must match this
swarming_wrapper = False

[env_config]
swarming = False # match
extra_obs = True
add_boey_obs = False # obs_wrapper must match this
full_resets = False
anneal = False
manual_reset = False
new_events = False
thatguys_cnn = False
max_episode_steps = 20480
rew_reset = 10240
reward_scale = 4
expl_scale = 5
reset_mem = 5
countdown = 11
inf_money = True
save_video = False
db_path = db/



; SPS: 5992.138
;     num_envs: 768
;     num_workers: 24
;     batch_size: 32
;     backend: Multiprocessing

; SPS: 5113.451
;     num_envs: 96
;     num_workers: 24
;     batch_size: 32
;     zero_copy: False
;     backend: Multiprocessing

; SPS: 5592.368
;     num_envs: 192
;     num_workers: 24
;     batch_size: 32
;     zero_copy: False
;     backend: Multiprocessing

; SPS: 5784.338
;     num_envs: 384
;     num_workers: 24
;     batch_size: 32
;     zero_copy: False
;     backend: Multiprocessing
